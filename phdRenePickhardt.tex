%%%MAKE TODO COMMAND!

\documentclass[â€¢]{book}
\title{A study of generalized language models.}
\author{Rene Pickhardt (expecting xxx -yyy pages content without structure)}
\date{\today}
\begin{document}
\maketitle
\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
%%%	Introduction
%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Foundations (do I need parts as a split level)}
if there where parts I'd have:
\begin{enumerate}
\item basics (theory+emperical)
\item working with GLM (application + indexing)
\item summary future work etc...
\end{enumerate}
\chapter{Introduction (x - y)}
this dissertation will mainly focus on \cite{own:typology:2013}
\section{Overview of the topic (x-y)}

\section{Running example (1 bis 2 pages)}
The core idea would be to choose an example or example setting of a person in his day life and show how he is confronted with all the various applications of generalized language models.
\begin{enumerate}
\item submitting text to a cellphone or search engine
\item handicaped people
\item speech recognition
\item text classification
\item WHAT ELSE?!? need to research applications
\end{enumerate}

\section{structure of the text (1-2)}

\section{Acknowledgements (1)}
\begin{itemize}
\item The community of the web providing this large mine of information. Especially the developers and everyone who publishes under an open licence and provides services. In particular the wikipedia foundation and stack exchange. 
\item My students from whom I learnt most
\item Steffen and Institute for creating and providing such a good environment
\item advisor Steffen, Thomas, Gerd.
\item Co authors for great discussion and good spirit (Thomas, Jonas, Till, Paul, Heinrich, Martin,)
\item readers of my blog (reading club, neo4j community, graph devroom)
\item External researchers from various conferences.\item friends
\item family and girlfriend

\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
%%%	Definitions and Overview
%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{A theory of generalized language models (xxx pages)}
\section{Introductionary example, definition of the probem}
Here we would just do a maximum likelihood estimation of $n$-grams. 
Introduce one or two example sentences (which have to be very well choosen)
\section{definition of skipped $n$-grams and differential notation}
\begin{enumerate}
\item notation. 
\item already have a motivation with some statistics taken from wikipedia ? 
\end{enumerate}
\section{smoothing tequniques for generalized language models}
\begin{enumerate}
\item kneser ney
\item laplace smoothing
\item any other smoothing technique?
\end{enumerate}
\section{Pascal triangle of generalized language models}
how we can understand skipped $n$-grams and what our point of view should be

\section{Standard language models as a special case of generalized language models}

\section{mathematical proof why generalized language models have to be better than language models}
only if I find one and if this is possible

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
%%%	Emperical study of generalized language models
%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{an emperical study of generalized language models}
\section{metrics for measuring}
\section{data sets}
\section{documentation to the GLM software toolkit}
\section{experimental setup}
\section{results}
\section{discussion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
%%%	APPLICATIONS of generalized language models
%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{applications of generalized language models}
\section{next word prediction paper}
maybe this year for cikm or www

\section{classification task}
together with ravi coote (don't know where)

\section{speech recognition}
find co-author maybe steffen can help

\section{semantic relatedness of words}
ESA work together with christoph schaefer

\section{machine translation}
also here not clear what to do and if co authors exist

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
%%%	INDEXING of Generalized language models
%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{indexing of generalized language models}
first basic question: will indexing depend on the application ? I guess it does. but it sure makes sense to to be able to store generalized language models.
\section{filtering GLM to acertain size}
shall I make this?
\section{a data structure to store GLM}
also here no ideas and results available

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
%%%	Conclusions / contributions
%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusion / Contributions (5 pages)}
\begin{itemize}
\item sparsity is solved
\item so far best known solution of some well known problems with rich applications. 
\end{itemize}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
%%%	Future work
%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Future work (5 pages)}
\section{more applications}

\section{better index structures}

\bibliographystyle{plain}
\bibliography{phdRenePickhardt}

\end{document}
